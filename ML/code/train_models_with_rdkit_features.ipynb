{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_df(df):\n",
    "    display(HTML(df.to_html()))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(estimator, X_eval, y_eval):\n",
    "    y_hat = estimator.predict(X_eval)\n",
    "    return np.sqrt(mean_squared_error(y_eval, y_hat))\n",
    "\n",
    "\n",
    "def r2(estimator, X_eval, y_eval):\n",
    "    y_hat = estimator.predict(X_eval)\n",
    "    return r2_score(y_eval, y_hat)\n",
    "\n",
    "\n",
    "def peason_r(estimator, X_eval, y_eval):\n",
    "    y_hat = estimator.predict(X_eval)\n",
    "    return np.corrcoef(y_eval, y_hat)[0, 1]\n",
    "\n",
    "\n",
    "def peason_r_metric(y_true, y_pred):\n",
    "    return np.corrcoef(y_true, y_pred)[0, 1]\n",
    "\n",
    "peason_r_score = make_scorer(peason_r_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_to_int(a_dict):\n",
    "    new_dict = copy.deepcopy(a_dict)\n",
    "    for k, v in new_dict.items():\n",
    "        if np.isclose(np.round(v), v):\n",
    "            new_dict[k] = int(new_dict[k])\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "def hyperopt_reg(regressor,\n",
    "                 params_tuned, \n",
    "                 X_train, y_train,\n",
    "                 num_eval,\n",
    "                 params_fixed=None,\n",
    "                 rstate=None):\n",
    "    \n",
    "    time_start = time.time()\n",
    "    if params_fixed is None:\n",
    "        params_fixed = {}\n",
    "    \n",
    "    def objective(params):\n",
    "        regressor.set_params(**params_fixed, **params)\n",
    "        # may use scoring='r2', \"neg_mean_squared_error\"\n",
    "        neg_mse = cross_val_score(regressor, X_train, y_train, cv=10, scoring=\"neg_mean_squared_error\").mean()\n",
    "        #r2 = cross_val_score(regressor, X_train, y_train, cv=10, scoring=\"r2\").mean()\n",
    "        #pearson_r = cross_val_score(regressor, X_train, y_train, cv=10, scoring=peason_r_score).mean()\n",
    "        return {\"loss\": -neg_mse, \"status\": STATUS_OK}\n",
    "    \n",
    "    if rstate is not None:\n",
    "        rstate = np.random.RandomState(rstate)\n",
    "        \n",
    "    trials = Trials()\n",
    "    best_params = fmin(objective, \n",
    "                      params_tuned, \n",
    "                      algo=tpe.suggest, \n",
    "                      max_evals=num_eval, \n",
    "                      trials=trials,\n",
    "                      rstate=rstate)\n",
    "    \n",
    "    best_params = whole_to_int(best_params)\n",
    "    best_model = regressor.set_params(**params_fixed, **best_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_elapse = time_end - time_start\n",
    "    print(\"Time elapsed: %0.5f s\" % time_elapse)\n",
    "    return trials, best_params, best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdXY = pd.read_csv(\"data/process/pdXY_labeled_rdkit_descriptors_104ft_imputed_std.csv\")\n",
    "\n",
    "PDY_COLS = [\"new_id\", \"smiles\", \"dG\", \"code\", \"train_test\", \"smiles_len\"]\n",
    "PDX_COLS = sorted([col for col in pdXY.columns if col not in PDY_COLS])\n",
    "print(\"PDX_COLS\", len(PDX_COLS))\n",
    "\n",
    "print(pdXY.shape)\n",
    "display_df(pdXY.head())\n",
    "\n",
    "\n",
    "X_train = pdXY.loc[pdXY[\"train_test\"] == \"train\", PDX_COLS].copy().values\n",
    "y_train = pdXY.loc[pdXY[\"train_test\"] == \"train\", \"dG\"].copy().values\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "X_test = pdXY.loc[pdXY[\"train_test\"] == \"test\", PDX_COLS].copy().values\n",
    "y_test = pdXY.loc[pdXY[\"train_test\"] == \"test\", \"dG\"].copy().values\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "X_val = pdXY.loc[pdXY[\"train_test\"] == \"val\", PDX_COLS].copy().values\n",
    "y_val = pdXY.loc[pdXY[\"train_test\"] == \"val\", \"dG\"].copy().values\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(np.concatenate([X_train, X_val], axis=0), np.concatenate([y_train, y_val], axis=0))\n",
    "\n",
    "print(\"Train RMSE:\", rmse(lr, X_train, y_train))\n",
    "print(\"Train Pearson's R:\", peason_r(lr, X_train, y_train))\n",
    "\n",
    "print(\"Val RMSE:\", rmse(lr, X_val, y_val))\n",
    "print(\"Val Pearson's R:\", peason_r(lr, X_val, y_val))\n",
    "\n",
    "print(\"Test RMSE:\", rmse(lr, X_test, y_test))\n",
    "print(\"Test Pearson's R:\", peason_r(lr, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "\n",
    "params = {\"alpha\": hp.loguniform(\"alpha\", np.log(1e-10), np.log(1e10)),}\n",
    "\n",
    "num_eval = 100\n",
    "\n",
    "trials, best_params, best_model = hyperopt_reg(ridge, params, \n",
    "                                               np.concatenate([X_train, X_val], axis=0), \n",
    "                                               np.concatenate([y_train, y_val], axis=0), \n",
    "                                               num_eval)\n",
    "print(\"best_params:\", best_params)\n",
    "\n",
    "print(\"Train RMSE:\", rmse(best_model, X_train, y_train))\n",
    "print(\"Train Pearson's R:\", peason_r(best_model, X_train, y_train))\n",
    "\n",
    "print(\"Val RMSE:\", rmse(lr, X_val, y_val))\n",
    "print(\"Val Pearson's R:\", peason_r(lr, X_val, y_val))\n",
    "\n",
    "print(\"Test RMSE:\", rmse(best_model, X_test, y_test))\n",
    "print(\"Test Pearson's R:\", peason_r(best_model, X_test, y_test))\n",
    "\n",
    "pickle.dump(best_model, open(\"models/lr/lr_01.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"models/lr/lr_01.pkl\", \"rb\"))\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_pred_df = pd.DataFrame({\"dG\": y_test, \"pred\": y_test_pred})\n",
    "test_pred_df.to_csv(\"results/lr/test_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 2, 14, 1)),\n",
    "    \"min_samples_split\": scope.int(hp.quniform(\"min_samples_split\", 2, 20, 2)),\n",
    "    \"min_samples_leaf\": scope.int(hp.quniform(\"min_samples_leaf\", 2, 20, 2)), \n",
    "    \"max_features\": scope.int(hp.quniform(\"max_features\", 10, 60, 5)),\n",
    "}\n",
    "\n",
    "params_fixed = {\n",
    "    \"n_estimators\": 1000\n",
    "}\n",
    "\n",
    "\n",
    "num_eval = 100\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "trials, best_params, best_model = hyperopt_reg(rf, params, np.concatenate([X_train, X_val], axis=0), \n",
    "                                               np.concatenate([y_train, y_val], axis=0), \n",
    "                                               num_eval, params_fixed=params_fixed)\n",
    "print(\"best_params:\", best_params)\n",
    "\n",
    "print(\"Train RMSE:\", rmse(best_model, X_train, y_train))\n",
    "print(\"Train Pearson's R:\", peason_r(best_model, X_train, y_train))\n",
    "\n",
    "print(\"Test RMSE:\", rmse(best_model, X_test, y_test))\n",
    "print(\"Test Pearson's R:\", peason_r(best_model, X_test, y_test))\n",
    "\n",
    "pickle.dump(best_model, open(\"models/rf/rf_01.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"models/rf/rf_01.pkl\", \"rb\"))\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_pred_df = pd.DataFrame({\"dG\": y_test, \"pred\": y_test_pred})\n",
    "test_pred_df.to_csv(\"results/rf/test_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 2, 8, 1)),\n",
    "    \"min_child_weight\": scope.int(hp.quniform(\"min_child_weight\", 1, 10, 1)), \n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.4, 1.0),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.4, 1.0),\n",
    "    \"reg_lambda\": hp.loguniform(\"reg_lambda\", np.log(0.00001), np.log(100)),\n",
    "    #\"reg_alpha\": hp.loguniform(\"reg_alpha\", np.log(0.001), np.log(1000)),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.0001), np.log(1.)),\n",
    "    #\"gamma\": hp.uniform(\"gamma\", 0., 5.),\n",
    "}\n",
    "\n",
    "params_fixed = {\n",
    "    \"tree_method\": \"gpu_hist\",\n",
    "    \"predictor\": \"gpu_predictor\",\n",
    "    \"n_estimators\": 300\n",
    "}\n",
    "\n",
    "\n",
    "num_eval = 100\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "trials, best_params, best_model = hyperopt_reg(xgb, params, \n",
    "                                               np.concatenate([X_train, X_val], axis=0),\n",
    "                                               np.concatenate([y_train, y_val], axis=0), \n",
    "                                               num_eval, params_fixed=params_fixed)\n",
    "print(\"best_params:\", best_params)\n",
    "\n",
    "print(\"Train RMSE:\", rmse(best_model, X_train, y_train))\n",
    "print(\"Train Pearson's R:\", peason_r(best_model, X_train, y_train))\n",
    "\n",
    "print(\"Test RMSE:\", rmse(best_model, X_test, y_test))\n",
    "print(\"Test Pearson's R:\", peason_r(best_model, X_test, y_test))\n",
    "\n",
    "pickle.dump(best_model, open(\"models/xgb/xbg_01.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
